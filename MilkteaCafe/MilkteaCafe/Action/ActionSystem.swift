import Foundation

/// Specifies which model to use for an Action.
enum ModelType {
    case thinking
    case chat
}

/// Defines a unit of work that can drive LLM generations, run custom code, and fire a post-action hook.
protocol Action {
    /// The full chat messages (history & prompt) to send to the LLM.
    var messages: [Message] { get }
    
    // The new message to add
    var message: Message { get }
    
    var systemPrompt: String { get }

    /// If true, the model's KV cache will be cleared before generation.
    var clearKVCache: Bool { get }

    /// Which underlying LlamaModel to use (thinking vs. chat).
    var modelType: ModelType { get }
    
    /// Prepares the action with dependency results just before execution
    /// - Parameter dependencies: A dictionary of results from dependency actions, keyed by action ID
    /// - Returns: Whether preparation was successful
    mutating func prepareForExecution(with dependencies: [String: Any]) async -> Bool

    /// Optional code hook to inspect or handle the raw LLM output.
    /// - Parameter response: The full string generated by the LLM.
    /// - Returns: A tuple where:
    ///   • didRun determines if `result` should be used instead of the raw response.
    ///   • result is the payload passed into postAction.
    func runCode(on response: String) -> (didRun: Bool, result: Any)

    /// Called exactly once per Action, after generation and runCode.
    /// - Parameter result: Either the LLM string (didRun=false) or a custom payload (didRun=true).
    func postAction(_ result: Any)
}

/// A type-erased Action allowing runCode and postAction closures
struct AnyAction: Action {
    let messages: [Message]
    private(set) var message: Message
    private(set) var systemPrompt: String
    let clearKVCache: Bool
    let modelType: ModelType
    let tokenFilter: TokenFilter?
    // New property for streaming UI updates
    let progressHandler: ((String) -> Void)?
    // New property for lazy preparation
    private let prepareActionClosure: ([String: Any]) async -> (Bool, Message?, String?)
    private let runCodeClosure: (String) -> (didRun: Bool, result: Any)
    private let postActionClosure: (Any) -> Void

    init(
        systemPrompt: String,
        messages: [Message],
        message: Message,
        clearKVCache: Bool,
        modelType: ModelType,
        tokenFilter: TokenFilter? = nil,
        // New optional parameter for handling streamed tokens
        progressHandler: ((String) -> Void)? = nil,
        // parameter for lazy preparation that can update both message and system prompt
        prepare: @escaping ([String: Any]) async -> (Bool, Message?, String?) = { _ in return (true, nil, nil) },
        runCode: @escaping (String) -> (didRun: Bool, result: Any),
        postAction: @escaping (Any) -> Void
    ) {
        self.messages = messages
        self.message = message
        self.systemPrompt = systemPrompt
        self.clearKVCache = clearKVCache
        self.modelType = modelType
        self.tokenFilter = tokenFilter
        self.progressHandler = progressHandler
        self.prepareActionClosure = prepare
        self.runCodeClosure = runCode
        self.postActionClosure = postAction
    }
    
    mutating func prepareForExecution(with dependencies: [String: Any]) async -> Bool {
        // Prepare action can return new message and/or new system prompt
        let (success, newMessage, newSystemPrompt) = await prepareActionClosure(dependencies)
        
        if success {
            // Update message if provided
            if let newMessage = newMessage {
                self.message = newMessage
                #if DEBUG
                LoggerService.shared.debug("AnyAction: Prepared message with dependencies")
                #endif
            }
            
            // Update system prompt if provided
            if let newSystemPrompt = newSystemPrompt {
                self.systemPrompt = newSystemPrompt
                #if DEBUG
                LoggerService.shared.debug("AnyAction: Prepared system prompt with dependencies (length: \(newSystemPrompt.count))")
                #endif
            }
        }
        
        return success
    }

    func runCode(on response: String) -> (didRun: Bool, result: Any) {
        runCodeClosure(response)
    }

    func postAction(_ result: Any) {
        DispatchQueue.main.async {
            self.postActionClosure(result)
        }
    }
}
